@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{marinatto2000quantum,
  title={A quantum approach to static games of complete information},
  author={Marinatto, Luca and Weber, Tullio},
  journal={Physics Letters A},
  volume={272},
  number={5-6},
  pages={291--303},
  year={2000},
  publisher={Elsevier}
}

@article{howard1960dynamic,
  title={Dynamic programming and markov processes.},
  author={Howard, Ronald A},
  year={1960},
  publisher={John Wiley}
}

@book{robert2013monte,
  title={Monte Carlo statistical methods},
  author={Robert, Christian and Casella, George},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{2007numanalysis,
  title={数值分析},
	author={林成森},
  year={2007},
  location = {北京},
  publisher={科学出版社}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S, et al},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009},
  organization={ACM}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@book{efron1994introduction,
    title={An introduction to the bootstrap},
    author={Efron, Bradley and Tibshirani, Robert J},
    year={1994},
    publisher={CRC press}
}

@book{ross1996stochastic,
    title={Stochastic processes},
    author={Ross, Sheldon M, et al},
    volume={2},
    year={1996},
    publisher={Wiley New York}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{macdermed2011markov,
  title={Markov games of incomplete information for multi-agent reinforcement learning},
  author={MacDermed, Liam and Isbell, Charles and Weiss, Lora},
  booktitle={Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence},
  year={2011}
}

@article{sandholm2010state,
  title={The state of solving large incomplete-information games, and application to poker},
  author={Sandholm, Tuomas},
  journal={AI Magazine},
  volume={31},
  number={4},
  pages={13--32},
  year={2010}
}

@book{2014wzjstatistics,
  title={数理统计教程},
  author={王兆军 and 邹长亮},
  year={2014},
  location = {北京},
  publisher={高等教育出版社}
}

@incollection{hecht1992theory,
  title={Theory of the backpropagation neural network},
  author={Hecht-Nielsen, Robert},
  booktitle={Neural networks for perception},
  pages={65--93},
  year={1992},
  publisher={Elsevier}
}

@article{edmonds1971matroids,
  title={Matroids and the greedy algorithm},
  author={Edmonds, Jack},
  journal={Mathematical programming},
  volume={1},
  number={1},
  pages={127--136},
  year={1971},
  publisher={Springer}
}

@inproceedings{li2017convergence,
  title={Convergence analysis of two-layer neural networks with relu activation},
  author={Li, Yuanzhi and Yuan, Yang},
  booktitle={Advances in Neural Information Processing Systems},
  pages={597--607},
  year={2017}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@book{murphy2012machine,
  title={Machine learning: a probabilistic perspective},
  author={Murphy, Kevin P},
  year={2012},
  publisher={MIT press}
}

@inproceedings{dahl2001reinforcement,
  title={A reinforcement learning algorithm applied to simplified two-player Texas Hold’em poker},
  author={Dahl, Fredrik A},
  booktitle={European Conference on Machine Learning},
  pages={85--96},
  year={2001},
  organization={Springer}
}

@book{2012statsmethods,
  title={统计学习方法},
  author={李航},
  location={北京},
  year={2012},
  publisher={清华大学出版社}
}

@book{cormen2009introduction,
  title={Introduction to algorithms},
  author={Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
  year={2009},
  publisher={MIT press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}
@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}
@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12519--12530},
  year={2019}
}
@article{asadi2019combating,
  title={Combating the compounding-error problem with a multi-step model},
  author={Asadi, Kavosh and Misra, Dipendra and Kim, Seungchan and Littman, Michel L},
  journal={arXiv preprint arXiv:1905.13320},
  year={2019}
}
@inproceedings{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13991--14002},
  year={2019}
}
@article{filos2020can,
  title={Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?},
  author={Filos, Angelos and Tigas, Panagiotis and McAllister, Rowan and Rhinehart, Nicholas and Levine, Sergey and Gal, Yarin},
  journal={arXiv preprint arXiv:2006.14911},
  year={2020}
}
@inproceedings{gal2016improving,
  title={Improving {PILCO} with {B}ayesian neural network dynamics models},
  author={Gal, Yarin and McAllister, Rowan and Rasmussen, Carl Edward},
  booktitle={Data-Efficient Machine Learning workshop, International Conference on Machine Learning},
  year={2016}
}
@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}
@article{kurutach2018model,
  title={Model-ensemble trust-region policy optimization},
  author={Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1802.10592},
  year={2018}
}
@incollection{sutton1990integrated,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning proceedings 1990},
  pages={216--224},
  year={1990},
  publisher={Elsevier}
}
@article{feinberg2018model,
  title={Model-based value estimation for efficient model-free reinforcement learning},
  author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.00101},
  year={2018}
}
@inproceedings{buckman2018sample,
  title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
  author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8224--8234},
  year={2018}
}
@book{zhou1998essentials,
  title={Essentials of robust control},
  author={Zhou, Kemin and Doyle, John Comstock},
  volume={104},
  year={1998},
  publisher={Prentice hall Upper Saddle River, NJ}
}
@article{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  journal={arXiv preprint arXiv:1703.02702},
  year={2017}
}
@article{tessler2019action,
  title={Action robust reinforcement learning and applications in continuous control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  journal={arXiv preprint arXiv:1901.09184},
  year={2019}
}
@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}
@book{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
  year={2013},
  publisher={now publishers}
}
@inproceedings{abbeel2006using,
  title={Using inaccurate models in reinforcement learning},
  author={Abbeel, Pieter and Quigley, Morgan and Ng, Andrew Y},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={1--8},
  year={2006}
}
@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}
@inproceedings{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1522--1530},
  year={2015}
}
@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}
@inproceedings{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}
@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}
@article{polydoros2017survey,
  title={Survey of model-based reinforcement learning: Applications on robotics},
  author={Polydoros, Athanasios S and Nalpantidis, Lazaros},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={86},
  number={2},
  pages={153--173},
  year={2017},
  publisher={Springer}
}
@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}
@inproceedings{degris2012model,
  title={Model-free reinforcement learning with continuous action in practice},
  author={Degris, Thomas and Pilarski, Patrick M and Sutton, Richard S},
  booktitle={2012 American Control Conference (ACC)},
  pages={2177--2182},
  year={2012},
  organization={IEEE}
}
@inproceedings{atkeson1997comparison,
  title={A comparison of direct and model-based reinforcement learning},
  author={Atkeson, Christopher G and Santamaria, Juan Carlos},
  booktitle={Proceedings of international conference on robotics and automation},
  volume={4},
  pages={3557--3564},
  year={1997},
  organization={IEEE}
}
@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}
@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}
@inproceedings{kormushev2010robot,
  title={Robot motor skill coordination with EM-based reinforcement learning},
  author={Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
  booktitle={2010 IEEE/RSJ international conference on intelligent robots and systems},
  pages={3232--3237},
  year={2010},
  organization={IEEE}
}
@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}
@inproceedings{zambaldi2018deep,
  title={Deep reinforcement learning with relational inductive biases},
  author={Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and others},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@article{quinonero2005unifying,
  title={A unifying view of sparse approximate Gaussian process regression},
  author={Qui{\~n}onero-Candela, Joaquin and Rasmussen, Carl Edward},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Dec},
  pages={1939--1959},
  year={2005}
}
@article{duan2007multi,
  title={Multi-model ensemble hydrologic prediction using Bayesian model averaging},
  author={Duan, Qingyun and Ajami, Newsha K and Gao, Xiaogang and Sorooshian, Soroosh},
  journal={Advances in Water Resources},
  volume={30},
  number={5},
  pages={1371--1386},
  year={2007},
  publisher={Elsevier}
}
@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}
@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  pages={1057--1063},
  year={1999}
}
@inproceedings{walsh2010integrating,
  title={Integrating Sample-Based Planning and Model-Based Reinforcement Learning.},
  author={Walsh, Thomas J and Goschin, Sergiu and Littman, Michael L},
  booktitle={AAAI},
  year={2010}
}
@inproceedings{peters2006policy,
  title={Policy gradient methods for robotics},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2219--2225},
  year={2006},
  organization={IEEE}
}
@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}
@article{moerland2020model,
  title={Model-based reinforcement learning: A survey},
  author={Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal={arXiv preprint arXiv:2006.16712},
  year={2020}
}
@article{chen2016evolution,
  title={The evolution of computing: AlphaGo},
  author={Chen, Jim X},
  journal={Computing in Science and Engineering},
  volume={18},
  number={4},
  pages={4--7},
  year={2016},
  publisher={IEEE Computer Society}
}
@inproceedings{williams2017information,
  title={Information theoretic MPC for model-based reinforcement learning},
  author={Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M and Boots, Byron and Theodorou, Evangelos A},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1714--1721},
  year={2017},
  organization={IEEE}
}
@article{shoham2003multi,
  title={Multi-agent reinforcement learning: a critical survey},
  author={Shoham, Yoav and Powers, Rob and Grenager, Trond},
  journal={Web manuscript},
  volume={2},
  year={2003}
}
@article{bu2019smart,
  title={A smart agriculture IoT system based on deep reinforcement learning},
  author={Bu, Fanyu and Wang, Xin},
  journal={Future Generation Computer Systems},
  volume={99},
  pages={500--507},
  year={2019},
  publisher={Elsevier}
}

@article{Piche2019,
    title = {{Probabilistic planning with sequential Monte Carlo methods}},
    year = {2019},
    journal = {7th International Conference on Learning Representations, ICLR 2019},
    author = {Pich{\'{e}}, Alexandre and Thomas, Valentin and Ibrahim, Cyril and Bengio, Yoshua and Pal, Chris},
    pages = {1--17}
}

@article{Chatzilygeroudis2020ATrials,
    title = {{A Survey on Policy Search Algorithms for Learning Robot Controllers in a Handful of Trials}},
    year = {2020},
    journal = {IEEE Transactions on Robotics},
    author = {Chatzilygeroudis, Konstantinos and Vassiliades, Vassilis and Stulp, Freek and Calinon, Sylvain and Mouret, Jean Baptiste},
    number = {2},
    pages = {328--347},
    volume = {36},
    publisher = {IEEE},
    doi = {10.1109/TRO.2019.2958211},
    issn = {19410468},
    arxivId = {1807.02303},
    keywords = {Autonomous agents, learning and adaptive systems, micro-data policy search (MDPS), robot learning}
}

@article{Luo2019AlgorithmicGuarantees,
    title = {{Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees}},
    year = {2019},
    journal = {7th International Conference on Learning Representations, ICLR 2019},
    author = {Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
    pages = {1--27},
    arxivId = {1807.03858}
}

@article{Maurer2005AlgorithmicMeta-learning,
    title = {{Algorithmic stability and meta-learning}},
    year = {2005},
    journal = {Journal of Machine Learning Research},
    author = {Maurer, Andreas},
    pages = {967--994},
    volume = {6},
    issn = {15337928},
    keywords = {Algorithmic stability, Learning to learn, Meta-learning}
}

@article{Pautrat2018BayesianSearch,
    title = {{Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search}},
    year = {2018},
    journal = {Proceedings - IEEE International Conference on Robotics and Automation},
    author = {Pautrat, Remi and Chatzilygeroudis, Konstantinos and Mouret, Jean Baptiste},
    pages = {7571--7578},
    isbn = {9781538630815},
    doi = {10.1109/ICRA.2018.8463197},
    issn = {10504729},
    arxivId = {1709.06919}
}

@article{Springenberg2016BayesianNetworks,
    title = {{Bayesian optimization with Robust Bayesian neural networks}},
    year = {2016},
    journal = {Advances in Neural Information Processing Systems},
    author = {Springenberg, Jost Tobias and Klein, Aaron and Falkner, Stefan and Hutter, Frank},
    number = {Section 4},
    pages = {4141--4149},
    issn = {10495258}
}

@article{WangBenchmarkingLearning,
    title = {{Benchmarking Model-Based Reinforcement Learning}},
    author = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
    pages = {1--25}
}

@article{Lai2020BidirectionalOptimization,
    title = {{Bidirectional Model-based Policy Optimization}},
    year = {2020},
    author = {Lai, Hang and Shen, Jian and Zhang, Weinan and Yu, Yong},
    url = {http://arxiv.org/abs/2007.01995},
    arxivId = {2007.01995}
}

@article{Filos2020CanShifts,
    title = {{Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?}},
    year = {2020},
    author = {Filos, Angelos and Tigas, Panagiotis and McAllister, Rowan and Rhinehart, Nicholas and Levine, Sergey and Gal, Yarin},
    url = {http://arxiv.org/abs/2006.14911},
    arxivId = {2006.14911}
}

@article{Ovadia2019CanShift,
    title = {{Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift}},
    year = {2019},
    author = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D and Nowozin, Sebastian and Dillon, Joshua V. and Lakshminarayanan, Balaji and Snoek, Jasper},
    number = {NeurIPS},
    url = {http://arxiv.org/abs/1906.02530},
    arxivId = {1906.02530}
}

@article{Francois-Lavet2019CombinedRepresentations,
    title = {{Combined Reinforcement Learning via Abstract Representations}},
    year = {2019},
    journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
    author = {Francois-Lavet, Vincent and Bengio, Yoshua and Precup, Doina and Pineau, Joelle},
    pages = {3582--3589},
    volume = {33},
    doi = {10.1609/aaai.v33i01.33013582},
    issn = {2159-5399},
    arxivId = {1809.04506},
    keywords = {deep reinforcement learning, deep RL, abstract rep}
}

@article{Lillicrap2016ContinuousLearning,
    title = {{Continuous control with deep reinforcement learning}},
    year = {2016},
    journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
    author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
    arxivId = {1509.02971}
}

@article{Chua2018DeepModels,
    title = {{Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}},
    year = {2018},
    journal = {Advances in Neural Information Processing Systems},
    author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
    number = {NeurIPS},
    pages = {4754--4765},
    volume = {2018-Decem},
    issn = {10495258},
    arxivId = {1805.12114}
}
@article{Hafner2019DreamImagination,
    title = {{Dream to Control: Learning Behaviors by Latent Imagination}},
    year = {2019},
    author = {Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
    pages = {1--20},
    url = {http://arxiv.org/abs/1912.01603},
    arxivId = {1912.01603}
}

@article{Sutton1991DynaReacting,
    title = {{Dyna, an integrated architecture for learning, planning, and reacting}},
    year = {1991},
    journal = {ACM SIGART Bulletin},
    author = {Sutton, Richard S.},
    number = {4},
    pages = {160--163},
    volume = {2},
    doi = {10.1145/122344.122377},
    issn = {0163-5719}
}

@article{Rajeswaran2016EPOpt:Ensembles,
    title = {{EPOpt: Learning Robust Neural Network Policies Using Model Ensembles}},
    year = {2016},
    author = {Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
    number = {2},
    pages = {1--15},
    url = {http://arxiv.org/abs/1610.01283},
    arxivId = {1610.01283}
}

@article{Munos2003ErrorIteration,
    title = {{Error Bounds for Approximate Policy Iteration}},
    year = {2003},
    journal = {Proceedings, Twentieth International Conference on Machine Learning},
    author = {Munos, Rémi},
    pages = {560--567},
    volume = {2},
    isbn = {1577351894}
}

@article{Menard2017FastLearning,
    title = {{Fast active learning for pure exploration in reinforcement learning}},
    year = {2017},
    author = {M{\'{e}}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Fabra, Universitat Pompeu and Kaufmann, Emilie and Leurent, Edouard and Valko, Michal and Paris, Deepmind},
    pages = {1--36},
    arxivId = {arXiv:2007.13442v1}
}

@article{Keramati2018FastLearning,
    title = {{Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning}},
    year = {2018},
    author = {Keramati, Ramtin and Whang, Jay and Cho, Patrick and Brunskill, Emma},
    pages = {1--13},
    url = {http://arxiv.org/abs/1806.00175},
    arxivId = {1806.00175}
}

@article{Andrychowicz2017HindsightReplay,
    title = {{Hindsight experience replay}},
    year = {2017},
    journal = {Advances in Neural Information Processing Systems},
    author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
    number = {Nips},
    pages = {5049--5059},
    volume = {2017-Decem},
    issn = {10495258},
    arxivId = {1707.01495}
}

@article{Chen2019LearningTrees,
    title = {{Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees}},
    year = {2019},
    author = {Chen, Binghong and Dai, Bo and Lin, Qinjie and Ye, Guo and Liu, Han and Song, Le},
    url = {http://arxiv.org/abs/1903.00070},
    arxivId = {1903.00070}
}

@article{Asadi2018LipschitzLearning,
    title = {{Lipschitz continuity in model-based reinforcement learning}},
    year = {2018},
    journal = {35th International Conference on Machine Learning, ICML 2018},
    author = {Asadi, Kavosh and Misra, Dipendra and Littman, Michael L.},
    number = {1},
    pages = {419--435},
    volume = {1},
    isbn = {9781510867963},
    arxivId = {1804.07193}
}

@article{ODonoghue2020MakingInference,
    title = {{Making Sense of Reinforcement Learning and Probabilistic Inference}},
    year = {2020},
    author = {O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
    pages = {1--16},
    url = {http://arxiv.org/abs/2001.00805},
    arxivId = {2001.00805}
}

@article{Bush2009ManifoldObservability,
    title = {{Manifold embeddings for model-based reinforcement learning under partial observability}},
    year = {2009},
    journal = {Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference},
    author = {Bush, Keith and Pineau, Joelle},
    pages = {189--197},
    isbn = {9781615679119}
}

@article{Xu2017Manifold-BasedVia,
    title = {{Manifold-Based Reinforcement Learning via}},
    year = {2017},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    author = {Xu, Xin and Huang, Zhenhua and Zuo, Lei and He, Haibo},
    number = {4},
    pages = {934--947},
    volume = {28},
    publisher = {IEEE},
    doi = {10.1109/TNNLS.2015.2505084}
}

@article{Schrittwieser2019MasteringModel,
    title = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
    year = {2019},
    author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
    pages = {1--21},
    url = {http://arxiv.org/abs/1911.08265},
    arxivId = {1911.08265}
}

@article{Lan2020MaxminQ-learning,
    title = {{Maxmin Q-learning: Controlling the Estimation Bias of Q-learning}},
    year = {2020},
    author = {Lan, Qingfeng and Pan, Yangchen and Fyshe, Alona and White, Martha},
    pages = {1--20},
    url = {http://arxiv.org/abs/2002.06487},
    arxivId = {2002.06487}
}

@article{Tan2020ModelLearning,
    title = {{Model Embedding Model-Based Reinforcement Learning}},
    year = {2020},
    author = {Tan, Xiaoyu and Qu, Chao and Xiong, Junwu and Zhang, James},
    pages = {1--25},
    url = {http://arxiv.org/abs/2006.09234},
    arxivId = {2006.09234}
}

@article{Clavera2020Model-AugmentedPaths,
    title = {{Model-Augmented Actor-Critic: Backpropagating through Paths}},
    year = {2020},
    author = {Clavera, Ignasi and Fu, Violet and Abbeel, Pieter},
    pages = {1--14},
    url = {http://arxiv.org/abs/2005.08068},
    arxivId = {2005.08068}
}

@article{Shyam2019Model-basedExploration,
    title = {{Model-based active exploration}},
    year = {2019},
    journal = {36th International Conference on Machine Learning, ICML 2019},
    author = {Shyam, Pranav and Jaskowski, Wojciech and Gomez, Faustino},
    pages = {10136--10152},
    volume = {2019-June},
    isbn = {9781510886988},
    arxivId = {1810.12162}
}

@article{Clavera2018Model-BasedOptimization,
    title = {{Model-Based Reinforcement Learning via Meta-Policy Optimization}},
    year = {2018},
    author = {Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
    number = {CoRL},
    url = {http://arxiv.org/abs/1809.05214},
    arxivId = {1809.05214},
    keywords = {meta-learning, model-based, model-free, reinforcement learning}
}

@article{Agarwal2019Model-BasedOptimal,
    title = {{Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal}},
    year = {2019},
    author = {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.},
    number = {1999},
    pages = {1--17},
    volume = {125},
    url = {http://arxiv.org/abs/1906.03804},
    arxivId = {1906.03804}
}

@article{Feinberg2018Model-BasedLearning,
    title = {{Model-Based Value Estimation for Efficient Model-Free Reinforcement Learning}},
    year = {2018},
    author = {Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I. and Gonzalez, Joseph E. and Levine, Sergey},
    url = {http://arxiv.org/abs/1803.00101},
    arxivId = {1803.00101}
}

@article{Fujimoto2019Off-policyExploration,
    title = {{Off-policy deep reinforcement learning without exploration}},
    year = {2019},
    journal = {36th International Conference on Machine Learning, ICML 2019},
    author = {Fujimoto, Scott and Meger, David and Precup, Doina},
    pages = {3599--3609},
    volume = {2019-June},
    isbn = {9781510886988},
    arxivId = {1812.02900}
}

@article{Islam2019Off-PolicyShift,
    title = {{Off-Policy Policy Gradient Algorithms by Constraining the State Distribution Shift}},
    year = {2019},
    author = {Islam, Riashat and Teru, Komal K. and Sharma, Deepak and Pineau, Joelle},
    pages = {1--13},
    url = {http://arxiv.org/abs/1911.06970},
    arxivId = {1911.06970}
}

@article{Tamar2009OptimizingSampling,
    title = {{Optimizing the CVaR via Sampling}},
    year = {2009},
    author = {Tamar, Aviv and Glassner, Yonatan and Mannor, Shie},
    number = {Fu 2006},
    arxivId = {arXiv:1404.3862v4}
}

@article{Tamar2015OptimizingSampling,
    title = {{Optimizing the CVaR via sampling}},
    year = {2015},
    journal = {Proceedings of the National Conference on Artificial Intelligence},
    author = {Tamar, Aviv and Glassner, Yonatan and Mannor, Shie},
    pages = {2993--2999},
    volume = {4},
    isbn = {9781577357025},
    arxivId = {1404.3862},
    keywords = {Novel Machine Learning Algorithms Track}
}

@article{Deisenroth2011PILCO:Search,
    title = {{PILCO: A model-based and data-efficient approach to policy search}},
    year = {2011},
    journal = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
    author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
    number = {July},
    pages = {465--472},
    isbn = {9781450306195}
}

@article{Du2019ProvablyOracle,
    title = {{Provably Efficient {\$}Q{\$}-learning with Function Approximation via Distribution Shift Error Checking Oracle}},
    year = {2019},
    author = {Du, Simon S. and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
    number = {NeurIPS},
    url = {http://arxiv.org/abs/1906.06321},
    arxivId = {1906.06321}
}

@article{Du2019ProvablyDecoding,
    title = {{Provably efficient RL with rich observations via latent state decoding}},
    year = {2019},
    journal = {36th International Conference on Machine Learning, ICML 2019},
    author = {Du, Simon S. and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dud{\'{i}}k, Miroslav and Langford, John},
    pages = {2971--3002},
    volume = {2019-June},
    isbn = {9781510886988},
    arxivId = {1901.09018}
}

@book{Brill1964QuinoxalineTrans-Decahydroquinoxalones-2,
    title = {{Quinoxaline Studies. XII. Stereodirective Syntheses of cis- and trans-Decahydroquinoxalines and cis- and trans-Decahydroquinoxalones-2}},
    year = {1964},
    booktitle = {Journal of Organic Chemistry},
    author = {Brill, Earl and Schultz, Harry P.},
    number = {3},
    pages = {579--581},
    volume = {29},
    isbn = {9780387310732},
    doi = {10.1021/jo01026a014},
    issn = {15206904}
}

@article{Levine2018ReinforcementReview,
    title = {{Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}},
    year = {2018},
    author = {Levine, Sergey},
    url = {http://arxiv.org/abs/1805.00909},
    arxivId = {1805.00909}
}

@article{Agarwal2019ReinforcementAlgorithms,
    title = {{Reinforcement Learning: Theory and Algorithms}},
    year = {2019},
    author = {Agarwal, Alekh and Jiang, Nan and Kakade, Sham M}
}

@article{Jin2020Reward-FreeLearning,
    title = {{Reward-Free Exploration for Reinforcement Learning}},
    year = {2020},
    author = {Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng},
    url = {http://arxiv.org/abs/2002.02794},
    arxivId = {2002.02794}
}

@article{Mankowitz2019RobustMisspecification,
    title = {{Robust Reinforcement Learning for Continuous Control with Model Misspecification}},
    year = {2019},
    author = {Mankowitz, Daniel J. and Levine, Nir and Jeong, Rae and Shi, Yuanyuan and Kay, Jackie and Abdolmaleki, Abbas and Springenberg, Jost Tobias and Mann, Timothy and Hester, Todd and Riedmiller, Martin},
    pages = {1--28},
    url = {http://arxiv.org/abs/1906.07516},
    arxivId = {1906.07516}
}

@article{McAllister2019RobustnessUncertainty,
    title = {{Robustness to out-of-distribution inputs via task-aware generative uncertainty}},
    year = {2019},
    journal = {Proceedings - IEEE International Conference on Robotics and Automation},
    author = {McAllister, Rowan and Kahn, Gregory and Clune, Jeff and Levine, Sergey},
    pages = {2083--2089},
    volume = {2019-May},
    isbn = {9781538660263},
    doi = {10.1109/ICRA.2019.8793552},
    issn = {10504729},
    arxivId = {1812.10687}
}

@article{Buckman2018Sample-efficientExpansion,
    title = {{Sample-efficient reinforcement learning with stochastic ensemble value expansion}},
    year = {2018},
    journal = {Advances in Neural Information Processing Systems},
    author = {Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
    number = {NeurIPS},
    pages = {8224--8234},
    volume = {2018-Decem},
    issn = {10495258},
    arxivId = {1807.01675}
}

@article{Zhao2020Self-PacedOutliers,
    title = {{Self-Paced Probabilistic Principal Component Analysis For Data With Outliers}},
    year = {2020},
    journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    author = {Zhao, Bowen and Xiao, Xi and Zhang, Wanpeng and Zhang, Bin and Gan, Guojun and Xia, Shutao},
    pages = {3737--3741},
    publisher = {IEEE},
    isbn = {9781509066315},
    doi = {10.1109/icassp40776.2020.9054487},
    arxivId = {1904.06546}
}

@book{Sutton1998SutSutton,
    title = {Reinforcement Learning: An Introduction},
    year = {1998},
    booktitle = {The Lancet},
    author = {Sutton, Richard S and Barto, Andrew G},
    number = {6685},
    pages = {675--676},
    volume = {258},
    isbn = {0262193981},
    doi = {10.1016/S0140-6736(51)92942-X},
    issn = {01406736},
    pmid = {17044734},
    arxivId = {1603.02199}
}

@article{Yu2018TowardsLearning,
    title = {{Towards sample efficient reinforcement learning}},
    year = {2018},
    journal = {IJCAI International Joint Conference on Artificial Intelligence},
    author = {Yu, Yang},
    pages = {5739--5743},
    volume = {2018-July},
    isbn = {9780999241127},
    doi = {10.24963/ijcai.2018/820},
    issn = {10450823},
    keywords = {Machine Learning: Reinforcement Learning}
}

@article{Abbeel2006UsingLearning,
    title = {{Using inaccurate models in reinforcement learning}},
    year = {2006},
    journal = {ACM International Conference Proceeding Series},
    author = {Abbeel, Pieter and Quigley, Morgan and Ng, Andrew Y.},
    pages = {1--8},
    volume = {148},
    isbn = {1595933832},
    doi = {10.1145/1143844.1143845}
}

@article{Oh2017ValueNetwork,
    title = {{Value prediction network}},
    year = {2017},
    journal = {Advances in Neural Information Processing Systems},
    author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
    number = {Nips},
    pages = {6119--6129},
    volume = {2017-Decem},
    issn = {10495258},
    arxivId = {1707.03497}
}

@article{Okada2019VariationalLearning,
    title = {{Variational Inference MPC for Bayesian Model-based Reinforcement Learning}},
    year = {2019},
    author = {Okada, Masashi and Taniguchi, Tadahiro},
    number = {CoRL},
    pages = {1--15},
    url = {http://arxiv.org/abs/1907.04202},
    arxivId = {1907.04202},
    keywords = {model predictive control, model-based rein-, variational inference}
}

@article{Marco2017VirtualOptimization,
    title = {{Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization}},
    year = {2017},
    journal = {Proceedings - IEEE International Conference on Robotics and Automation},
    author = {Marco, Alonso and Berkenkamp, Felix and Hennig, Philipp and Schoellig, Angela P. and Krause, Andreas and Schaal, Stefan and Trimpe, Sebastian},
    pages = {1557--1563},
    isbn = {9781509046331},
    doi = {10.1109/ICRA.2017.7989186},
    issn = {10504729},
    arxivId = {1703.01250}
}

@article{Blundell2015WeightNetworks,
    title = {{Weight uncertainty in neural networks}},
    year = {2015},
    journal = {32nd International Conference on Machine Learning, ICML 2015},
    author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
    pages = {1613--1622},
    volume = {2},
    isbn = {9781510810587},
    arxivId = {1505.05424}
}

@article{Janner2019WhenOptimization,
    title = {{When to Trust Your Model: Model-Based Policy Optimization}},
    year = {2019},
    author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
    number = {NeurIPS},
    url = {http://arxiv.org/abs/1906.08253},
    arxivId = {1906.08253}
}