@book{sutton2018reinforcement,
  title={Reinforcement learning: An introduction},
  author={Sutton, Richard S and Barto, Andrew G},
  year={2018},
  publisher={MIT press}
}

@article{marinatto2000quantum,
  title={A quantum approach to static games of complete information},
  author={Marinatto, Luca and Weber, Tullio},
  journal={Physics Letters A},
  volume={272},
  number={5-6},
  pages={291--303},
  year={2000},
  publisher={Elsevier}
}

@article{white1963dynamic,
  title={Dynamic programming, Markov chains, and the method of successive approximations},
  author={White, Douglas J},
  journal={Journal of Mathematical Analysis and Applications},
  volume={6},
  number={3},
  pages={373--376},
  year={1963},
  publisher={Academic Press}
}

@book{robert2013monte,
  title={Monte Carlo statistical methods},
  author={Robert, Christian and Casella, George},
  year={2013},
  publisher={Springer Science \& Business Media}
}

@book{2007numanalysis,
  title={数值分析},
	author={林成森},
  year={2007},
  location = {北京},
  publisher={科学出版社}
}

@incollection{bottou2010large,
  title={Large-scale machine learning with stochastic gradient descent},
  author={Bottou, L{\'e}on},
  booktitle={Proceedings of COMPSTAT'2010},
  pages={177--186},
  year={2010},
  publisher={Springer}
}

@inproceedings{sutton2009fast,
  title={Fast gradient-descent methods for temporal-difference learning with linear function approximation},
  author={Sutton, Richard S, et al},
  booktitle={Proceedings of the 26th Annual International Conference on Machine Learning},
  pages={993--1000},
  year={2009},
  organization={ACM}
}

@inproceedings{tsitsiklis1997analysis,
  title={Analysis of temporal-diffference learning with function approximation},
  author={Tsitsiklis, John N and Van Roy, Benjamin},
  booktitle={Advances in neural information processing systems},
  pages={1075--1081},
  year={1997}
}

@book{goodfellow2016deep,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@book{efron1994introduction,
    title={An introduction to the bootstrap},
    author={Efron, Bradley and Tibshirani, Robert J},
    year={1994},
    publisher={CRC press}
}

@book{ross1996stochastic,
    title={Stochastic processes},
    author={Ross, Sheldon M, et al},
    volume={2},
    year={1996},
    publisher={Wiley New York}
}

@article{mnih2013playing,
  title={Playing atari with deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
  journal={arXiv preprint arXiv:1312.5602},
  year={2013}
}

@article{silver2017mastering,
  title={Mastering the game of go without human knowledge},
  author={Silver, David and Schrittwieser, Julian and Simonyan, Karen and Antonoglou, Ioannis and Huang, Aja and Guez, Arthur and Hubert, Thomas and Baker, Lucas and Lai, Matthew and Bolton, Adrian and others},
  journal={Nature},
  volume={550},
  number={7676},
  pages={354},
  year={2017},
  publisher={Nature Publishing Group}
}

@inproceedings{macdermed2011markov,
  title={Markov games of incomplete information for multi-agent reinforcement learning},
  author={MacDermed, Liam and Isbell, Charles and Weiss, Lora},
  booktitle={Workshops at the Twenty-Fifth AAAI Conference on Artificial Intelligence},
  year={2011}
}

@article{sandholm2010state,
  title={The state of solving large incomplete-information games, and application to poker},
  author={Sandholm, Tuomas},
  journal={AI Magazine},
  volume={31},
  number={4},
  pages={13--32},
  year={2010}
}

@book{2014wzjstatistics,
  title={数理统计教程},
  author={王兆军 and 邹长亮},
  year={2014},
  location = {北京},
  publisher={高等教育出版社}
}

@incollection{hecht1992theory,
  title={Theory of the backpropagation neural network},
  author={Hecht-Nielsen, Robert},
  booktitle={Neural networks for perception},
  pages={65--93},
  year={1992},
  publisher={Elsevier}
}

@article{edmonds1971matroids,
  title={Matroids and the greedy algorithm},
  author={Edmonds, Jack},
  journal={Mathematical programming},
  volume={1},
  number={1},
  pages={127--136},
  year={1971},
  publisher={Springer}
}

@inproceedings{li2017convergence,
  title={Convergence analysis of two-layer neural networks with relu activation},
  author={Li, Yuanzhi and Yuan, Yang},
  booktitle={Advances in Neural Information Processing Systems},
  pages={597--607},
  year={2017}
}

@article{srivastava2014dropout,
  title={Dropout: a simple way to prevent neural networks from overfitting},
  author={Srivastava, Nitish and Hinton, Geoffrey and Krizhevsky, Alex and Sutskever, Ilya and Salakhutdinov, Ruslan},
  journal={The Journal of Machine Learning Research},
  volume={15},
  number={1},
  pages={1929--1958},
  year={2014},
  publisher={JMLR. org}
}

@book{bishop2006pattern,
  title={Pattern recognition and machine learning},
  author={Bishop, Christopher M},
  year={2006},
  publisher={springer}
}

@book{murphy2012machine,
  title={Machine learning: a probabilistic perspective},
  author={Murphy, Kevin P},
  year={2012},
  publisher={MIT press}
}

@inproceedings{dahl2001reinforcement,
  title={A reinforcement learning algorithm applied to simplified two-player Texas Hold’em poker},
  author={Dahl, Fredrik A},
  booktitle={European Conference on Machine Learning},
  pages={85--96},
  year={2001},
  organization={Springer}
}

@book{cormen2009introduction,
  title={Introduction to algorithms},
  author={Cormen, Thomas H and Leiserson, Charles E and Rivest, Ronald L and Stein, Clifford},
  year={2009},
  publisher={MIT press}
}

@article{mnih2015human,
  title={Human-level control through deep reinforcement learning},
  author={Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A and Veness, Joel and Bellemare, Marc G and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K and Ostrovski, Georg and others},
  journal={nature},
  volume={518},
  number={7540},
  pages={529--533},
  year={2015},
  publisher={Nature Publishing Group}
}
@article{silver2016mastering,
  title={Mastering the game of Go with deep neural networks and tree search},
  author={Silver, David and Huang, Aja and Maddison, Chris J and Guez, Arthur and Sifre, Laurent and Van Den Driessche, George and Schrittwieser, Julian and Antonoglou, Ioannis and Panneershelvam, Veda and Lanctot, Marc and others},
  journal={nature},
  volume={529},
  number={7587},
  pages={484--489},
  year={2016},
  publisher={Nature Publishing Group}
}
@article{lillicrap2015continuous,
  title={Continuous control with deep reinforcement learning},
  author={Lillicrap, Timothy P and Hunt, Jonathan J and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
  journal={arXiv preprint arXiv:1509.02971},
  year={2015}
}
@inproceedings{deisenroth2011pilco,
  title={PILCO: A model-based and data-efficient approach to policy search},
  author={Deisenroth, Marc and Rasmussen, Carl E},
  booktitle={Proceedings of the 28th International Conference on machine learning (ICML-11)},
  pages={465--472},
  year={2011}
}
@article{levine2016end,
  title={End-to-end training of deep visuomotor policies},
  author={Levine, Sergey and Finn, Chelsea and Darrell, Trevor and Abbeel, Pieter},
  journal={The Journal of Machine Learning Research},
  volume={17},
  number={1},
  pages={1334--1373},
  year={2016},
  publisher={JMLR. org}
}
@inproceedings{janner2019trust,
  title={When to trust your model: Model-based policy optimization},
  author={Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
  booktitle={Advances in Neural Information Processing Systems},
  pages={12519--12530},
  year={2019}
}
@article{asadi2019combating,
  title={Combating the compounding-error problem with a multi-step model},
  author={Asadi, Kavosh and Misra, Dipendra and Kim, Seungchan and Littman, Michel L},
  journal={arXiv preprint arXiv:1905.13320},
  year={2019}
}
@inproceedings{ovadia2019can,
  title={Can you trust your model's uncertainty? Evaluating predictive uncertainty under dataset shift},
  author={Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, David and Nowozin, Sebastian and Dillon, Joshua and Lakshminarayanan, Balaji and Snoek, Jasper},
  booktitle={Advances in Neural Information Processing Systems},
  pages={13991--14002},
  year={2019}
}
@article{filos2020can,
  title={Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?},
  author={Filos, Angelos and Tigas, Panagiotis and McAllister, Rowan and Rhinehart, Nicholas and Levine, Sergey and Gal, Yarin},
  journal={arXiv preprint arXiv:2006.14911},
  year={2020}
}
@inproceedings{gal2016improving,
  title={Improving {PILCO} with {B}ayesian neural network dynamics models},
  author={Gal, Yarin and McAllister, Rowan and Rasmussen, Carl Edward},
  booktitle={Data-Efficient Machine Learning workshop, International Conference on Machine Learning},
  year={2016}
}
@article{kurutach2018model,
  title={Model-ensemble trust-region policy optimization},
  author={Kurutach, Thanard and Clavera, Ignasi and Duan, Yan and Tamar, Aviv and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1802.10592},
  year={2018}
}
@incollection{sutton1990integrated,
  title={Integrated architectures for learning, planning, and reacting based on approximating dynamic programming},
  author={Sutton, Richard S},
  booktitle={Machine learning proceedings 1990},
  pages={216--224},
  year={1990},
  publisher={Elsevier}
}
@article{feinberg2018model,
  title={Model-based value estimation for efficient model-free reinforcement learning},
  author={Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I and Gonzalez, Joseph E and Levine, Sergey},
  journal={arXiv preprint arXiv:1803.00101},
  year={2018}
}
@inproceedings{buckman2018sample,
  title={Sample-efficient reinforcement learning with stochastic ensemble value expansion},
  author={Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
  booktitle={Advances in Neural Information Processing Systems},
  pages={8224--8234},
  year={2018}
}
@book{zhou1998essentials,
  title={Essentials of robust control},
  author={Zhou, Kemin and Doyle, John Comstock},
  volume={104},
  year={1998},
  publisher={Prentice hall Upper Saddle River, NJ}
}
@article{pinto2017robust,
  title={Robust adversarial reinforcement learning},
  author={Pinto, Lerrel and Davidson, James and Sukthankar, Rahul and Gupta, Abhinav},
  journal={arXiv preprint arXiv:1703.02702},
  year={2017}
}
@article{tessler2019action,
  title={Action robust reinforcement learning and applications in continuous control},
  author={Tessler, Chen and Efroni, Yonathan and Mannor, Shie},
  journal={arXiv preprint arXiv:1901.09184},
  year={2019}
}
@article{schulman2015high,
  title={High-dimensional continuous control using generalized advantage estimation},
  author={Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  journal={arXiv preprint arXiv:1506.02438},
  year={2015}
}
@book{deisenroth2013survey,
  title={A survey on policy search for robotics},
  author={Deisenroth, Marc Peter and Neumann, Gerhard and Peters, Jan},
  year={2013},
  publisher={now publishers}
}
@inproceedings{abbeel2006using,
  title={Using inaccurate models in reinforcement learning},
  author={Abbeel, Pieter and Quigley, Morgan and Ng, Andrew Y},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={1--8},
  year={2006}
}
@article{haarnoja2018soft,
  title={Soft actor-critic: Off-policy maximum entropy deep reinforcement learning with a stochastic actor},
  author={Haarnoja, Tuomas and Zhou, Aurick and Abbeel, Pieter and Levine, Sergey},
  journal={arXiv preprint arXiv:1801.01290},
  year={2018}
}
@inproceedings{todorov2012mujoco,
  title={Mujoco: A physics engine for model-based control},
  author={Todorov, Emanuel and Erez, Tom and Tassa, Yuval},
  booktitle={2012 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={5026--5033},
  year={2012},
  organization={IEEE}
}
@article{kaelbling1996reinforcement,
  title={Reinforcement learning: A survey},
  author={Kaelbling, Leslie Pack and Littman, Michael L and Moore, Andrew W},
  journal={Journal of artificial intelligence research},
  volume={4},
  pages={237--285},
  year={1996}
}
@inproceedings{tan1993multi,
  title={Multi-agent reinforcement learning: Independent vs. cooperative agents},
  author={Tan, Ming},
  booktitle={Proceedings of the tenth international conference on machine learning},
  pages={330--337},
  year={1993}
}
@article{szepesvari2010algorithms,
  title={Algorithms for reinforcement learning},
  author={Szepesv{\'a}ri, Csaba},
  journal={Synthesis lectures on artificial intelligence and machine learning},
  volume={4},
  number={1},
  pages={1--103},
  year={2010},
  publisher={Morgan \& Claypool Publishers}
}
@article{polydoros2017survey,
  title={Survey of model-based reinforcement learning: Applications on robotics},
  author={Polydoros, Athanasios S and Nalpantidis, Lazaros},
  journal={Journal of Intelligent \& Robotic Systems},
  volume={86},
  number={2},
  pages={153--173},
  year={2017},
  publisher={Springer}
}
@article{kober2013reinforcement,
  title={Reinforcement learning in robotics: A survey},
  author={Kober, Jens and Bagnell, J Andrew and Peters, Jan},
  journal={The International Journal of Robotics Research},
  volume={32},
  number={11},
  pages={1238--1274},
  year={2013},
  publisher={SAGE Publications Sage UK: London, England}
}
@article{arulkumaran2017deep,
  title={Deep reinforcement learning: A brief survey},
  author={Arulkumaran, Kai and Deisenroth, Marc Peter and Brundage, Miles and Bharath, Anil Anthony},
  journal={IEEE Signal Processing Magazine},
  volume={34},
  number={6},
  pages={26--38},
  year={2017},
  publisher={IEEE}
}
@inproceedings{degris2012model,
  title={Model-free reinforcement learning with continuous action in practice},
  author={Degris, Thomas and Pilarski, Patrick M and Sutton, Richard S},
  booktitle={2012 American Control Conference (ACC)},
  pages={2177--2182},
  year={2012},
  organization={IEEE}
}
@inproceedings{atkeson1997comparison,
  title={A comparison of direct and model-based reinforcement learning},
  author={Atkeson, Christopher G and Santamaria, Juan Carlos},
  booktitle={Proceedings of international conference on robotics and automation},
  volume={4},
  pages={3557--3564},
  year={1997},
  organization={IEEE}
}
@article{garcia2015comprehensive,
  title={A comprehensive survey on safe reinforcement learning},
  author={Garc{\i}a, Javier and Fern{\'a}ndez, Fernando},
  journal={Journal of Machine Learning Research},
  volume={16},
  number={1},
  pages={1437--1480},
  year={2015}
}
@article{sallab2017deep,
  title={Deep reinforcement learning framework for autonomous driving},
  author={Sallab, Ahmad EL and Abdou, Mohammed and Perot, Etienne and Yogamani, Senthil},
  journal={Electronic Imaging},
  volume={2017},
  number={19},
  pages={70--76},
  year={2017},
  publisher={Society for Imaging Science and Technology}
}
@inproceedings{kormushev2010robot,
  title={Robot motor skill coordination with EM-based reinforcement learning},
  author={Kormushev, Petar and Calinon, Sylvain and Caldwell, Darwin G},
  booktitle={2010 IEEE/RSJ international conference on intelligent robots and systems},
  pages={3232--3237},
  year={2010},
  organization={IEEE}
}
@inproceedings{munos2016safe,
  title={Safe and efficient off-policy reinforcement learning},
  author={Munos, R{\'e}mi and Stepleton, Tom and Harutyunyan, Anna and Bellemare, Marc},
  booktitle={Advances in Neural Information Processing Systems},
  pages={1054--1062},
  year={2016}
}
@article{schulman2017proximal,
  title={Proximal policy optimization algorithms},
  author={Schulman, John and Wolski, Filip and Dhariwal, Prafulla and Radford, Alec and Klimov, Oleg},
  journal={arXiv preprint arXiv:1707.06347},
  year={2017}
}
@article{lin1992self,
  title={Self-improving reactive agents based on reinforcement learning, planning and teaching},
  author={Lin, Long-Ji},
  journal={Machine learning},
  volume={8},
  number={3-4},
  pages={293--321},
  year={1992},
  publisher={Springer}
}
@inproceedings{zambaldi2018deep,
  title={Deep reinforcement learning with relational inductive biases},
  author={Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and others},
  booktitle={International Conference on Learning Representations},
  year={2018}
}
@article{quinonero2005unifying,
  title={A unifying view of sparse approximate Gaussian process regression},
  author={Qui{\~n}onero-Candela, Joaquin and Rasmussen, Carl Edward},
  journal={Journal of Machine Learning Research},
  volume={6},
  number={Dec},
  pages={1939--1959},
  year={2005}
}
@article{duan2007multi,
  title={Multi-model ensemble hydrologic prediction using Bayesian model averaging},
  author={Duan, Qingyun and Ajami, Newsha K and Gao, Xiaogang and Sorooshian, Soroosh},
  journal={Advances in Water Resources},
  volume={30},
  number={5},
  pages={1371--1386},
  year={2007},
  publisher={Elsevier}
}
@inproceedings{silver2014deterministic,
  title={Deterministic policy gradient algorithms},
  author={Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
  year={2014}
}
@article{sutton1999policy,
  title={Policy gradient methods for reinforcement learning with function approximation},
  author={Sutton, Richard S and McAllester, David and Singh, Satinder and Mansour, Yishay},
  journal={Advances in neural information processing systems},
  volume={12},
  pages={1057--1063},
  year={1999}
}
@inproceedings{walsh2010integrating,
  title={Integrating Sample-Based Planning and Model-Based Reinforcement Learning.},
  author={Walsh, Thomas J and Goschin, Sergiu and Littman, Michael L},
  booktitle={AAAI},
  year={2010}
}
@inproceedings{peters2006policy,
  title={Policy gradient methods for robotics},
  author={Peters, Jan and Schaal, Stefan},
  booktitle={2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
  pages={2219--2225},
  year={2006},
  organization={IEEE}
}
@article{kaiser2019model,
  title={Model-based reinforcement learning for atari},
  author={Kaiser, Lukasz and Babaeizadeh, Mohammad and Milos, Piotr and Osinski, Blazej and Campbell, Roy H and Czechowski, Konrad and Erhan, Dumitru and Finn, Chelsea and Kozakowski, Piotr and Levine, Sergey and others},
  journal={arXiv preprint arXiv:1903.00374},
  year={2019}
}
@article{moerland2020model,
  title={Model-based reinforcement learning: A survey},
  author={Moerland, Thomas M and Broekens, Joost and Jonker, Catholijn M},
  journal={arXiv preprint arXiv:2006.16712},
  year={2020}
}
@article{chen2016evolution,
  title={The evolution of computing: AlphaGo},
  author={Chen, Jim X},
  journal={Computing in Science and Engineering},
  volume={18},
  number={4},
  pages={4--7},
  year={2016},
  publisher={IEEE Computer Society}
}
@inproceedings{williams2017information,
  title={Information theoretic MPC for model-based reinforcement learning},
  author={Williams, Grady and Wagener, Nolan and Goldfain, Brian and Drews, Paul and Rehg, James M and Boots, Byron and Theodorou, Evangelos A},
  booktitle={2017 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={1714--1721},
  year={2017},
  organization={IEEE}
}
@article{shoham2003multi,
  title={Multi-agent reinforcement learning: a critical survey},
  author={Shoham, Yoav and Powers, Rob and Grenager, Trond},
  journal={Web manuscript},
  volume={2},
  year={2003}
}
@article{bu2019smart,
  title={A smart agriculture IoT system based on deep reinforcement learning},
  author={Bu, Fanyu and Wang, Xin},
  journal={Future Generation Computer Systems},
  volume={99},
  pages={500--507},
  year={2019},
  publisher={Elsevier}
}

@article{Piche2019,
    title = {{Probabilistic planning with sequential Monte Carlo methods}},
    year = {2019},
    journal = {7th International Conference on Learning Representations, ICLR 2019},
    author = {Pich{\'{e}}, Alexandre and Thomas, Valentin and Ibrahim, Cyril and Bengio, Yoshua and Pal, Chris},
    pages = {1--17}
}

@article{Chatzilygeroudis2020ATrials,
    title = {{A Survey on Policy Search Algorithms for Learning Robot Controllers in a Handful of Trials}},
    year = {2020},
    journal = {IEEE Transactions on Robotics},
    author = {Chatzilygeroudis, Konstantinos and Vassiliades, Vassilis and Stulp, Freek and Calinon, Sylvain and Mouret, Jean Baptiste},
    number = {2},
    pages = {328--347},
    volume = {36},
    publisher = {IEEE},
    doi = {10.1109/TRO.2019.2958211},
    issn = {19410468},
    arxivId = {1807.02303},
    keywords = {Autonomous agents, learning and adaptive systems, micro-data policy search (MDPS), robot learning}
}

@article{Luo2019AlgorithmicGuarantees,
    title = {{Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees}},
    year = {2019},
    journal = {7th International Conference on Learning Representations, ICLR 2019},
    author = {Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
    pages = {1--27},
    arxivId = {1807.03858}
}

@article{Maurer2005AlgorithmicMeta-learning,
    title = {{Algorithmic stability and meta-learning}},
    year = {2005},
    journal = {Journal of Machine Learning Research},
    author = {Maurer, Andreas},
    pages = {967--994},
    volume = {6},
    issn = {15337928},
    keywords = {Algorithmic stability, Learning to learn, Meta-learning}
}

@article{Pautrat2018BayesianSearch,
    title = {{Bayesian Optimization with Automatic Prior Selection for Data-Efficient Direct Policy Search}},
    year = {2018},
    journal = {Proceedings - IEEE International Conference on Robotics and Automation},
    author = {Pautrat, Remi and Chatzilygeroudis, Konstantinos and Mouret, Jean Baptiste},
    pages = {7571--7578},
    isbn = {9781538630815},
    doi = {10.1109/ICRA.2018.8463197},
    issn = {10504729},
    arxivId = {1709.06919}
}

@article{Springenberg2016BayesianNetworks,
    title = {{Bayesian optimization with Robust Bayesian neural networks}},
    year = {2016},
    journal = {Advances in Neural Information Processing Systems},
    author = {Springenberg, Jost Tobias and Klein, Aaron and Falkner, Stefan and Hutter, Frank},
    number = {Section 4},
    pages = {4141--4149},
    issn = {10495258}
}

@article{WangBenchmarkingLearning,
    title = {{Benchmarking Model-Based Reinforcement Learning}},
    author = {Wang, Tingwu and Bao, Xuchan and Clavera, Ignasi and Hoang, Jerrick and Wen, Yeming and Langlois, Eric and Zhang, Shunshi and Zhang, Guodong and Abbeel, Pieter and Ba, Jimmy},
    pages = {1--25}
}

@article{Lai2020BidirectionalOptimization,
    title = {{Bidirectional Model-based Policy Optimization}},
    year = {2020},
    author = {Lai, Hang and Shen, Jian and Zhang, Weinan and Yu, Yong},
    url = {http://arxiv.org/abs/2007.01995},
    arxivId = {2007.01995}
}

@article{Filos2020CanShifts,
    title = {{Can Autonomous Vehicles Identify, Recover From, and Adapt to Distribution Shifts?}},
    year = {2020},
    author = {Filos, Angelos and Tigas, Panagiotis and McAllister, Rowan and Rhinehart, Nicholas and Levine, Sergey and Gal, Yarin},
    url = {http://arxiv.org/abs/2006.14911},
    arxivId = {2006.14911}
}

@article{Ovadia2019CanShift,
    title = {{Can You Trust Your Model's Uncertainty? Evaluating Predictive Uncertainty Under Dataset Shift}},
    year = {2019},
    author = {Ovadia, Yaniv and Fertig, Emily and Ren, Jie and Nado, Zachary and Sculley, D and Nowozin, Sebastian and Dillon, Joshua V. and Lakshminarayanan, Balaji and Snoek, Jasper},
    number = {NeurIPS},
    url = {http://arxiv.org/abs/1906.02530},
    arxivId = {1906.02530}
}

@article{Francois-Lavet2019CombinedRepresentations,
    title = {{Combined Reinforcement Learning via Abstract Representations}},
    year = {2019},
    journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
    author = {Francois-Lavet, Vincent and Bengio, Yoshua and Precup, Doina and Pineau, Joelle},
    pages = {3582--3589},
    volume = {33},
    doi = {10.1609/aaai.v33i01.33013582},
    issn = {2159-5399},
    arxivId = {1809.04506},
    keywords = {deep reinforcement learning, deep RL, abstract rep}
}

@article{Lillicrap2016ContinuousLearning,
    title = {{Continuous control with deep reinforcement learning}},
    year = {2016},
    journal = {4th International Conference on Learning Representations, ICLR 2016 - Conference Track Proceedings},
    author = {Lillicrap, Timothy P. and Hunt, Jonathan J. and Pritzel, Alexander and Heess, Nicolas and Erez, Tom and Tassa, Yuval and Silver, David and Wierstra, Daan},
    arxivId = {1509.02971}
}

@article{Chua2018DeepModels,
    title = {{Deep Reinforcement Learning in a Handful of Trials using Probabilistic Dynamics Models}},
    year = {2018},
    journal = {Advances in Neural Information Processing Systems},
    author = {Chua, Kurtland and Calandra, Roberto and McAllister, Rowan and Levine, Sergey},
    number = {NeurIPS},
    pages = {4754--4765},
    volume = {2018-Decem},
    issn = {10495258},
    arxivId = {1805.12114}
}
@article{Hafner2019DreamImagination,
    title = {{Dream to Control: Learning Behaviors by Latent Imagination}},
    year = {2019},
    author = {Hafner, Danijar and Lillicrap, Timothy and Ba, Jimmy and Norouzi, Mohammad},
    pages = {1--20},
    url = {http://arxiv.org/abs/1912.01603},
    arxivId = {1912.01603}
}

@article{Sutton1991DynaReacting,
    title = {{Dyna, an integrated architecture for learning, planning, and reacting}},
    year = {1991},
    journal = {ACM SIGART Bulletin},
    author = {Sutton, Richard S.},
    number = {4},
    pages = {160--163},
    volume = {2},
    doi = {10.1145/122344.122377},
    issn = {0163-5719}
}

@article{Munos2003ErrorIteration,
    title = {{Error Bounds for Approximate Policy Iteration}},
    year = {2003},
    journal = {Proceedings, Twentieth International Conference on Machine Learning},
    author = {Munos, Rémi},
    pages = {560--567},
    volume = {2},
    isbn = {1577351894}
}

@article{Menard2017FastLearning,
    title = {{Fast active learning for pure exploration in reinforcement learning}},
    year = {2017},
    author = {M{\'{e}}nard, Pierre and Domingues, Omar Darwiche and Jonsson, Anders and Fabra, Universitat Pompeu and Kaufmann, Emilie and Leurent, Edouard and Valko, Michal and Paris, Deepmind},
    pages = {1--36},
    arxivId = {arXiv:2007.13442v1}
}

@article{Keramati2018FastLearning,
    title = {{Fast Exploration with Simplified Models and Approximately Optimistic Planning in Model Based Reinforcement Learning}},
    year = {2018},
    author = {Keramati, Ramtin and Whang, Jay and Cho, Patrick and Brunskill, Emma},
    pages = {1--13},
    url = {http://arxiv.org/abs/1806.00175},
    arxivId = {1806.00175}
}

@article{Andrychowicz2017HindsightReplay,
    title = {{Hindsight experience replay}},
    year = {2017},
    journal = {Advances in Neural Information Processing Systems},
    author = {Andrychowicz, Marcin and Wolski, Filip and Ray, Alex and Schneider, Jonas and Fong, Rachel and Welinder, Peter and McGrew, Bob and Tobin, Josh and Abbeel, Pieter and Zaremba, Wojciech},
    number = {Nips},
    pages = {5049--5059},
    volume = {2017-Decem},
    issn = {10495258},
    arxivId = {1707.01495}
}

@article{Chen2019LearningTrees,
    title = {{Learning to Plan in High Dimensions via Neural Exploration-Exploitation Trees}},
    year = {2019},
    author = {Chen, Binghong and Dai, Bo and Lin, Qinjie and Ye, Guo and Liu, Han and Song, Le},
    url = {http://arxiv.org/abs/1903.00070},
    arxivId = {1903.00070}
}

@article{Asadi2018LipschitzLearning,
    title = {{Lipschitz continuity in model-based reinforcement learning}},
    year = {2018},
    journal = {35th International Conference on Machine Learning, ICML 2018},
    author = {Asadi, Kavosh and Misra, Dipendra and Littman, Michael L.},
    number = {1},
    pages = {419--435},
    volume = {1},
    isbn = {9781510867963},
    arxivId = {1804.07193}
}

@article{ODonoghue2020MakingInference,
    title = {{Making Sense of Reinforcement Learning and Probabilistic Inference}},
    year = {2020},
    author = {O'Donoghue, Brendan and Osband, Ian and Ionescu, Catalin},
    pages = {1--16},
    url = {http://arxiv.org/abs/2001.00805},
    arxivId = {2001.00805}
}

@article{Bush2009ManifoldObservability,
    title = {{Manifold embeddings for model-based reinforcement learning under partial observability}},
    year = {2009},
    journal = {Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference},
    author = {Bush, Keith and Pineau, Joelle},
    pages = {189--197},
    isbn = {9781615679119}
}

@article{Xu2017Manifold-BasedVia,
    title = {{Manifold-Based Reinforcement Learning via}},
    year = {2017},
    journal = {IEEE Transactions on Neural Networks and Learning Systems},
    author = {Xu, Xin and Huang, Zhenhua and Zuo, Lei and He, Haibo},
    number = {4},
    pages = {934--947},
    volume = {28},
    publisher = {IEEE},
    doi = {10.1109/TNNLS.2015.2505084}
}

@article{Schrittwieser2019MasteringModel,
    title = {{Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model}},
    year = {2019},
    author = {Schrittwieser, Julian and Antonoglou, Ioannis and Hubert, Thomas and Simonyan, Karen and Sifre, Laurent and Schmitt, Simon and Guez, Arthur and Lockhart, Edward and Hassabis, Demis and Graepel, Thore and Lillicrap, Timothy and Silver, David},
    pages = {1--21},
    url = {http://arxiv.org/abs/1911.08265},
    arxivId = {1911.08265}
}

@article{Lan2020MaxminQ-learning,
    title = {{Maxmin Q-learning: Controlling the Estimation Bias of Q-learning}},
    year = {2020},
    author = {Lan, Qingfeng and Pan, Yangchen and Fyshe, Alona and White, Martha},
    pages = {1--20},
    url = {http://arxiv.org/abs/2002.06487},
    arxivId = {2002.06487}
}

@article{Tan2020ModelLearning,
    title = {{Model Embedding Model-Based Reinforcement Learning}},
    year = {2020},
    author = {Tan, Xiaoyu and Qu, Chao and Xiong, Junwu and Zhang, James},
    pages = {1--25},
    url = {http://arxiv.org/abs/2006.09234},
    arxivId = {2006.09234}
}

@article{Clavera2020Model-AugmentedPaths,
    title = {{Model-Augmented Actor-Critic: Backpropagating through Paths}},
    year = {2020},
    author = {Clavera, Ignasi and Fu, Violet and Abbeel, Pieter},
    pages = {1--14},
    url = {http://arxiv.org/abs/2005.08068},
    arxivId = {2005.08068}
}

@article{Shyam2019Model-basedExploration,
    title = {{Model-based active exploration}},
    year = {2019},
    journal = {36th International Conference on Machine Learning, ICML 2019},
    author = {Shyam, Pranav and Jaskowski, Wojciech and Gomez, Faustino},
    pages = {10136--10152},
    volume = {2019-June},
    isbn = {9781510886988},
    arxivId = {1810.12162}
}

@article{Clavera2018Model-BasedOptimization,
    title = {{Model-Based Reinforcement Learning via Meta-Policy Optimization}},
    year = {2018},
    author = {Clavera, Ignasi and Rothfuss, Jonas and Schulman, John and Fujita, Yasuhiro and Asfour, Tamim and Abbeel, Pieter},
    number = {CoRL},
    url = {http://arxiv.org/abs/1809.05214},
    arxivId = {1809.05214},
    keywords = {meta-learning, model-based, model-free, reinforcement learning}
}

@article{Agarwal2019Model-BasedOptimal,
    title = {{Model-Based Reinforcement Learning with a Generative Model is Minimax Optimal}},
    year = {2019},
    author = {Agarwal, Alekh and Kakade, Sham and Yang, Lin F.},
    number = {1999},
    pages = {1--17},
    volume = {125},
    url = {http://arxiv.org/abs/1906.03804},
    arxivId = {1906.03804}
}

@article{Feinberg2018Model-BasedLearning,
    title = {{Model-Based Value Estimation for Efficient Model-Free Reinforcement Learning}},
    year = {2018},
    author = {Feinberg, Vladimir and Wan, Alvin and Stoica, Ion and Jordan, Michael I. and Gonzalez, Joseph E. and Levine, Sergey},
    url = {http://arxiv.org/abs/1803.00101},
    arxivId = {1803.00101}
}

@article{Fujimoto2019Off-policyExploration,
    title = {{Off-policy deep reinforcement learning without exploration}},
    year = {2019},
    journal = {36th International Conference on Machine Learning, ICML 2019},
    author = {Fujimoto, Scott and Meger, David and Precup, Doina},
    pages = {3599--3609},
    volume = {2019-June},
    isbn = {9781510886988},
    arxivId = {1812.02900}
}

@article{Islam2019Off-PolicyShift,
    title = {{Off-Policy Policy Gradient Algorithms by Constraining the State Distribution Shift}},
    year = {2019},
    author = {Islam, Riashat and Teru, Komal K. and Sharma, Deepak and Pineau, Joelle},
    pages = {1--13},
    url = {http://arxiv.org/abs/1911.06970},
    arxivId = {1911.06970}
}

@article{Tamar2015OptimizingSampling,
    title = {{Optimizing the CVaR via sampling}},
    year = {2015},
    journal = {Proceedings of the National Conference on Artificial Intelligence},
    author = {Tamar, Aviv and Glassner, Yonatan and Mannor, Shie},
    pages = {2993--2999},
    volume = {4},
    isbn = {9781577357025},
    arxivId = {1404.3862},
    keywords = {Novel Machine Learning Algorithms Track}
}

@article{Deisenroth2011PILCO:Search,
    title = {{PILCO: A model-based and data-efficient approach to policy search}},
    year = {2011},
    journal = {Proceedings of the 28th International Conference on Machine Learning, ICML 2011},
    author = {Deisenroth, Marc Peter and Rasmussen, Carl Edward},
    number = {July},
    pages = {465--472},
    isbn = {9781450306195}
}

@article{Du2019ProvablyOracle,
    title = {{Provably Efficient {\$}Q{\$}-learning with Function Approximation via Distribution Shift Error Checking Oracle}},
    year = {2019},
    author = {Du, Simon S. and Luo, Yuping and Wang, Ruosong and Zhang, Hanrui},
    number = {NeurIPS},
    url = {http://arxiv.org/abs/1906.06321},
    arxivId = {1906.06321}
}

@article{Du2019ProvablyDecoding,
    title = {{Provably efficient RL with rich observations via latent state decoding}},
    year = {2019},
    journal = {36th International Conference on Machine Learning, ICML 2019},
    author = {Du, Simon S. and Krishnamurthy, Akshay and Jiang, Nan and Agarwal, Alekh and Dud{\'{i}}k, Miroslav and Langford, John},
    pages = {2971--3002},
    volume = {2019-June},
    isbn = {9781510886988},
    arxivId = {1901.09018}
}

@book{Brill1964QuinoxalineTrans-Decahydroquinoxalones-2,
    title = {{Quinoxaline Studies. XII. Stereodirective Syntheses of cis- and trans-Decahydroquinoxalines and cis- and trans-Decahydroquinoxalones-2}},
    year = {1964},
    booktitle = {Journal of Organic Chemistry},
    author = {Brill, Earl and Schultz, Harry P.},
    number = {3},
    pages = {579--581},
    volume = {29},
    isbn = {9780387310732},
    doi = {10.1021/jo01026a014},
    issn = {15206904}
}

@article{Levine2018ReinforcementReview,
    title = {{Reinforcement Learning and Control as Probabilistic Inference: Tutorial and Review}},
    year = {2018},
    author = {Levine, Sergey},
    url = {http://arxiv.org/abs/1805.00909},
    arxivId = {1805.00909}
}

@article{Agarwal2019ReinforcementAlgorithms,
    title = {{Reinforcement Learning: Theory and Algorithms}},
    year = {2019},
    author = {Agarwal, Alekh and Jiang, Nan and Kakade, Sham M}
}

@article{Jin2020Reward-FreeLearning,
    title = {{Reward-Free Exploration for Reinforcement Learning}},
    year = {2020},
    author = {Jin, Chi and Krishnamurthy, Akshay and Simchowitz, Max and Yu, Tiancheng},
    url = {http://arxiv.org/abs/2002.02794},
    arxivId = {2002.02794}
}

@article{Mankowitz2019RobustMisspecification,
    title = {{Robust Reinforcement Learning for Continuous Control with Model Misspecification}},
    year = {2019},
    author = {Mankowitz, Daniel J. and Levine, Nir and Jeong, Rae and Shi, Yuanyuan and Kay, Jackie and Abdolmaleki, Abbas and Springenberg, Jost Tobias and Mann, Timothy and Hester, Todd and Riedmiller, Martin},
    pages = {1--28},
    url = {http://arxiv.org/abs/1906.07516},
    arxivId = {1906.07516}
}

@article{McAllister2019RobustnessUncertainty,
    title = {{Robustness to out-of-distribution inputs via task-aware generative uncertainty}},
    year = {2019},
    journal = {Proceedings - IEEE International Conference on Robotics and Automation},
    author = {McAllister, Rowan and Kahn, Gregory and Clune, Jeff and Levine, Sergey},
    pages = {2083--2089},
    volume = {2019-May},
    isbn = {9781538660263},
    doi = {10.1109/ICRA.2019.8793552},
    issn = {10504729},
    arxivId = {1812.10687}
}

@article{Buckman2018Sample-efficientExpansion,
    title = {{Sample-efficient reinforcement learning with stochastic ensemble value expansion}},
    year = {2018},
    journal = {Advances in Neural Information Processing Systems},
    author = {Buckman, Jacob and Hafner, Danijar and Tucker, George and Brevdo, Eugene and Lee, Honglak},
    number = {NeurIPS},
    pages = {8224--8234},
    volume = {2018-Decem},
    issn = {10495258},
    arxivId = {1807.01675}
}

@article{Zhao2020Self-PacedOutliers,
    title = {{Self-Paced Probabilistic Principal Component Analysis For Data With Outliers}},
    year = {2020},
    journal = {ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
    author = {Zhao, Bowen and Xiao, Xi and Zhang, Wanpeng and Zhang, Bin and Gan, Guojun and Xia, Shutao},
    pages = {3737--3741},
    publisher = {IEEE},
    isbn = {9781509066315},
    doi = {10.1109/icassp40776.2020.9054487},
    arxivId = {1904.06546}
}

@book{Sutton1998SutSutton,
    title = {Reinforcement Learning: An Introduction},
    year = {1998},
    booktitle = {The Lancet},
    author = {Sutton, Richard S and Barto, Andrew G},
    number = {6685},
    pages = {675--676},
    volume = {258},
    isbn = {0262193981},
    doi = {10.1016/S0140-6736(51)92942-X},
    issn = {01406736},
    pmid = {17044734},
    arxivId = {1603.02199}
}

@article{Yu2018TowardsLearning,
    title = {{Towards sample efficient reinforcement learning}},
    year = {2018},
    journal = {IJCAI International Joint Conference on Artificial Intelligence},
    author = {Yu, Yang},
    pages = {5739--5743},
    volume = {2018-July},
    isbn = {9780999241127},
    doi = {10.24963/ijcai.2018/820},
    issn = {10450823},
    keywords = {Machine Learning: Reinforcement Learning}
}

@article{Abbeel2006UsingLearning,
    title = {{Using inaccurate models in reinforcement learning}},
    year = {2006},
    journal = {ACM International Conference Proceeding Series},
    author = {Abbeel, Pieter and Quigley, Morgan and Ng, Andrew Y.},
    pages = {1--8},
    volume = {148},
    isbn = {1595933832},
    doi = {10.1145/1143844.1143845}
}

@article{Oh2017ValueNetwork,
    title = {{Value prediction network}},
    year = {2017},
    journal = {Advances in Neural Information Processing Systems},
    author = {Oh, Junhyuk and Singh, Satinder and Lee, Honglak},
    number = {Nips},
    pages = {6119--6129},
    volume = {2017-Decem},
    issn = {10495258},
    arxivId = {1707.03497}
}

@article{Okada2019VariationalLearning,
    title = {{Variational Inference MPC for Bayesian Model-based Reinforcement Learning}},
    year = {2019},
    author = {Okada, Masashi and Taniguchi, Tadahiro},
    number = {CoRL},
    pages = {1--15},
    url = {http://arxiv.org/abs/1907.04202},
    arxivId = {1907.04202},
    keywords = {model predictive control, model-based rein-, variational inference}
}

@article{Marco2017VirtualOptimization,
    title = {{Virtual vs. real: Trading off simulations and physical experiments in reinforcement learning with Bayesian optimization}},
    year = {2017},
    journal = {Proceedings - IEEE International Conference on Robotics and Automation},
    author = {Marco, Alonso and Berkenkamp, Felix and Hennig, Philipp and Schoellig, Angela P. and Krause, Andreas and Schaal, Stefan and Trimpe, Sebastian},
    pages = {1557--1563},
    isbn = {9781509046331},
    doi = {10.1109/ICRA.2017.7989186},
    issn = {10504729},
    arxivId = {1703.01250}
}

@article{Blundell2015WeightNetworks,
    title = {{Weight uncertainty in neural networks}},
    year = {2015},
    journal = {32nd International Conference on Machine Learning, ICML 2015},
    author = {Blundell, Charles and Cornebise, Julien and Kavukcuoglu, Koray and Wierstra, Daan},
    pages = {1613--1622},
    volume = {2},
    isbn = {9781510810587},
    arxivId = {1505.05424}
}

@article{Janner2019WhenOptimization,
    title = {{When to Trust Your Model: Model-Based Policy Optimization}},
    year = {2019},
    author = {Janner, Michael and Fu, Justin and Zhang, Marvin and Levine, Sergey},
    number = {NeurIPS},
    url = {http://arxiv.org/abs/1906.08253},
    arxivId = {1906.08253}
}
@inproceedings{schaul2016prioritized,
	Author = {Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
	Booktitle = {International Conference on Learning Representations},
	Date-Modified = {2019-11-09 00:37:43 -0500},
	Title = {{Prioritized Experience Replay}},
	Year = {2016}}
@inproceedings{cai2017real,
  title={Real-time bidding by reinforcement learning in display advertising},
  author={Cai, Han and Ren, Kan and Zhang, Weinan and Malialis, Kleanthis and Wang, Jun and Yu, Yong and Guo, Defeng},
  booktitle={Proceedings of the Tenth ACM International Conference on Web Search and Data Mining},
  pages={661--670},
  year={2017}
}
@inproceedings{wang2018reinforcement,
  title={A reinforcement learning framework for explainable recommendation},
  author={Wang, Xiting and Chen, Yiru and Yang, Jie and Wu, Le and Wu, Zhengtao and Xie, Xing},
  booktitle={2018 IEEE international conference on data mining (ICDM)},
  pages={587--596},
  year={2018},
  organization={IEEE}
}
@article{li2016deep,
  title={Deep reinforcement learning for dialogue generation},
  author={Li, Jiwei and Monroe, Will and Ritter, Alan and Galley, Michel and Gao, Jianfeng and Jurafsky, Dan},
  journal={arXiv preprint arXiv:1606.01541},
  year={2016}
}
@article{riedmiller2009reinforcement,
  title={Reinforcement learning for robot soccer},
  author={Riedmiller, Martin and Gabel, Thomas and Hafner, Roland and Lange, Sascha},
  journal={Autonomous Robots},
  volume={27},
  number={1},
  pages={55--73},
  year={2009},
  publisher={Springer}
}
@inproceedings{zhang2021robust,
  title={Robust Model-based Reinforcement Learning for Autonomous Greenhouse Control},
  author={Zhang, Wanpeng and Cao, Xiaoyan and Yao, Yao and An, Zhicheng and Xiao, Xi and Luo, Dijun},
  booktitle={Asian Conference on Machine Learning},
  pages={1208--1223},
  year={2021},
  organization={PMLR}
}
@article{osband2014model,
  title={Model-based reinforcement learning and the eluder dimension},
  author={Osband, Ian and Van Roy, Benjamin},
  journal={Advances in Neural Information Processing Systems},
  volume={27},
  year={2014}
}
@inproceedings{junges2016safety,
  title={Safety-constrained reinforcement learning for MDPs},
  author={Junges, Sebastian and Jansen, Nils and Dehnert, Christian and Topcu, Ufuk and Katoen, Joost-Pieter},
  booktitle={International Conference on Tools and Algorithms for the Construction and Analysis of Systems},
  pages={130--146},
  year={2016},
  organization={Springer}
}
@article{watkins1992q,
  title={Q-learning},
  author={Watkins, Christopher JCH and Dayan, Peter},
  journal={Machine learning},
  volume={8},
  number={3},
  pages={279--292},
  year={1992},
  publisher={Springer}
}
@article{schaul2015prioritized,
  title={Prioritized experience replay},
  author={Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David},
  journal={arXiv preprint arXiv:1511.05952},
  year={2015}
}
@article{tesauro1995temporal,
  title={Temporal difference learning and TD-Gammon},
  author={Tesauro, Gerald and others},
  journal={Communications of the ACM},
  volume={38},
  number={3},
  pages={58--68},
  year={1995}
}
@article{tokdar2010importance,
  title={Importance sampling: a review},
  author={Tokdar, Surya T and Kass, Robert E},
  journal={Wiley Interdisciplinary Reviews: Computational Statistics},
  volume={2},
  number={1},
  pages={54--60},
  year={2010},
  publisher={Wiley Online Library}
}
@inproceedings{lee2021optidice,
  title={Optidice: Offline policy optimization via stationary distribution correction estimation},
  author={Lee, Jongmin and Jeon, Wonseok and Lee, Byungjun and Pineau, Joelle and Kim, Kee-Eung},
  booktitle={International Conference on Machine Learning},
  pages={6120--6130},
  year={2021},
  organization={PMLR}
}
@article{zhang2017deeper,
  title={A deeper look at experience replay},
  author={Zhang, Shangtong and Sutton, Richard S},
  journal={arXiv preprint arXiv:1712.01275},
  year={2017}
}
@inproceedings{pieters2016q,
  title={Q-learning with experience replay in a dynamic environment},
  author={Pieters, Mathijs and Wiering, Marco A},
  booktitle={2016 IEEE Symposium Series on Computational Intelligence (SSCI)},
  pages={1--8},
  year={2016},
  organization={IEEE}
}
@inproceedings{de2015importance,
  title={The importance of experience replay database composition in deep reinforcement learning},
  author={De Bruin, Tim and Kober, Jens and Tuyls, Karl and Babu{\v{s}}ka, Robert},
  booktitle={Deep reinforcement learning workshop, NIPS},
  year={2015}
}
@article{rajeswaran2016epopt,
  title={Epopt: Learning robust neural network policies using model ensembles},
  author={Rajeswaran, Aravind and Ghotra, Sarvjeet and Ravindran, Balaraman and Levine, Sergey},
  journal={arXiv preprint arXiv:1610.01283},
  year={2016}
}
@article{luo2018algorithmic,
  title={Algorithmic framework for model-based deep reinforcement learning with theoretical guarantees},
  author={Luo, Yuping and Xu, Huazhe and Li, Yuanzhi and Tian, Yuandong and Darrell, Trevor and Ma, Tengyu},
  journal={arXiv preprint arXiv:1807.03858},
  year={2018}
}
@inproceedings{cheng2019end,
  title={End-to-end safe reinforcement learning through barrier functions for safety-critical continuous control tasks},
  author={Cheng, Richard and Orosz, G{\'a}bor and Murray, Richard M and Burdick, Joel W},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  number={01},
  pages={3387--3395},
  year={2019}
}
@inproceedings{zhang2020cautious,
  title={Cautious adaptation for reinforcement learning in safety-critical settings},
  author={Zhang, Jesse and Cheung, Brian and Finn, Chelsea and Levine, Sergey and Jayaraman, Dinesh},
  booktitle={International Conference on Machine Learning},
  pages={11055--11065},
  year={2020},
  organization={PMLR}
}
@article{chow2015risk,
  title={Risk-sensitive and robust decision-making: a cvar optimization approach},
  author={Chow, Yinlam and Tamar, Aviv and Mannor, Shie and Pavone, Marco},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{zhang2021mbdp,
  title={MBDP: A Model-based Approach to Achieve both Robustness and Sample Efficiency via Double Dropout Planning},
  author={Zhang, Wanpeng and Xiao, Xi and Yao, Yao and Chen, Mingzhe and Luo, Dijun},
  journal={arXiv preprint arXiv:2108.01295},
  year={2021}
}
@inproceedings{yao2021sample,
  title={Sample Efficient Reinforcement Learning via Model-Ensemble Exploration and Exploitation},
  author={Yao, Yao and Xiao, Li and An, Zhicheng and Zhang, Wanpeng and Luo, Dijun},
  booktitle={2021 IEEE International Conference on Robotics and Automation (ICRA)},
  pages={4202--4208},
  year={2021},
  organization={IEEE}
}
@inproceedings{an2021simulator,
  title={A Simulator-based Planning Framework for Optimizing Autonomous Greenhouse Control Strategy},
  author={An, Zhicheng and Cao, Xiaoyan and Yao, Yao and Zhang, Wanpeng and Li, Lanqing and Wang, Yue and Guo, Shihui and Luo, Dijun},
  booktitle={Proceedings of the International Conference on Automated Planning and Scheduling},
  pages={436--444},
  year={2021}
}
@article{cao2021igrow,
  title={iGrow: A Smart Agriculture Solution to Autonomous Greenhouse Control},
  author={Cao, Xiaoyan and Yao, Yao and Li, Lanqing and Zhang, Wanpeng and An, Zhicheng and Zhang, Zhong and Guo, Shihui and Xiao, Li and Cao, Xiaoyu and Luo, Dijun},
  journal={arXiv preprint arXiv:2107.05464},
  year={2021}
}
@article{sathya2013comparison,
  title={Comparison of supervised and unsupervised learning algorithms for pattern classification},
  author={Sathya, Ramadass and Abraham, Annamma and others},
  journal={International Journal of Advanced Research in Artificial Intelligence},
  volume={2},
  number={2},
  pages={34--38},
  year={2013},
  publisher={Citeseer}
}
@article{zhou2018brief,
  title={A brief introduction to weakly supervised learning},
  author={Zhou, Zhi-Hua},
  journal={National science review},
  volume={5},
  number={1},
  pages={44--53},
  year={2018},
  publisher={Oxford University Press}
}
@inproceedings{holcomb2018overview,
  title={Overview on deepmind and its alphago zero ai},
  author={Holcomb, Sean D and Porter, William K and Ault, Shaun V and Mao, Guifen and Wang, Jin},
  booktitle={Proceedings of the 2018 international conference on big data and education},
  pages={67--71},
  year={2018}
}
@article{ling2015application,
  title={Application of reinforcement learning for security enhancement in cognitive radio networks},
  author={Ling, Mee Hong and Yau, Kok-Lim Alvin and Qadir, Junaid and Poh, Geong Sen and Ni, Qiang},
  journal={Applied Soft Computing},
  volume={37},
  pages={809--829},
  year={2015},
  publisher={Elsevier}
}
@inproceedings{pal2020brief,
  title={Brief survey of model-based reinforcement learning techniques},
  author={Pal, Constantin-Valentin and Leon, Florin},
  booktitle={2020 24th International Conference on System Theory, Control and Computing (ICSTCC)},
  pages={92--97},
  year={2020},
  organization={IEEE}
}
@article{xiong2016combining,
  title={Combining deep reinforcement learning and safety based control for autonomous driving},
  author={Xiong, Xi and Wang, Jianqiang and Zhang, Fang and Li, Keqiang},
  journal={arXiv preprint arXiv:1612.00147},
  year={2016}
}
@inproceedings{ferdowsi2018robust,
  title={Robust deep reinforcement learning for security and safety in autonomous vehicle systems},
  author={Ferdowsi, Aidin and Challita, Ursula and Saad, Walid and Mandayam, Narayan B},
  booktitle={2018 21st International Conference on Intelligent Transportation Systems (ITSC)},
  pages={307--312},
  year={2018},
  organization={IEEE}
}
@inproceedings{wei2021non,
  title={Non-stationary reinforcement learning without prior knowledge: An optimal black-box approach},
  author={Wei, Chen-Yu and Luo, Haipeng},
  booktitle={Conference on Learning Theory},
  pages={4300--4354},
  year={2021},
  organization={PMLR}
}
@article{mousavi2020black,
  title={Black-box off-policy estimation for infinite-horizon reinforcement learning},
  author={Mousavi, Ali and Li, Lihong and Liu, Qiang and Zhou, Denny},
  journal={arXiv preprint arXiv:2003.11126},
  year={2020}
}
@article{berkenkamp2017safe,
  title={Safe model-based reinforcement learning with stability guarantees},
  author={Berkenkamp, Felix and Turchetta, Matteo and Schoellig, Angela and Krause, Andreas},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}
@article{jin2020stability,
  title={Stability-certified reinforcement learning: A control-theoretic perspective},
  author={Jin, Ming and Lavaei, Javad},
  journal={IEEE Access},
  volume={8},
  pages={229086--229100},
  year={2020},
  publisher={IEEE}
}
@article{grondman2012survey,
  title={A survey of actor-critic reinforcement learning: Standard and natural policy gradients},
  author={Grondman, Ivo and Busoniu, Lucian and Lopes, Gabriel AD and Babuska, Robert},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={42},
  number={6},
  pages={1291--1307},
  year={2012},
  publisher={IEEE}
}
@article{adam2011experience,
  title={Experience replay for real-time reinforcement learning control},
  author={Adam, Sander and Busoniu, Lucian and Babuska, Robert},
  journal={IEEE Transactions on Systems, Man, and Cybernetics, Part C (Applications and Reviews)},
  volume={42},
  number={2},
  pages={201--212},
  year={2011},
  publisher={IEEE}
}
@article{rockafellar2002conditional,
  title={Conditional value-at-risk for general loss distributions},
  author={Rockafellar, R Tyrrell and Uryasev, Stanislav},
  journal={Journal of banking \& finance},
  volume={26},
  number={7},
  pages={1443--1471},
  year={2002},
  publisher={Elsevier}
}